# EchoFrame

**EchoFrame** is a Multi-Modal AI Pipeline that seamlessly integrates computer vision, natural language processing, and speech synthesis to transform static images into immersive audio stories.

This project demonstrates the future of AI â€” moving from pixels to spoken narrative using an intelligent and composable multi-model AI workflow.

---

## ðŸŒ Architecture Overview

```
Image â†’ Object & Pose Detection â†’ Scene Reasoning â†’ Story Generation â†’ Speech
       (YOLOv8 + MediaPipe)       (Custom Logic)      (LLaMA 3.2 via Ollama)    (gTTS)
```

---

## âœ¨ Key Features

- ðŸ” **Computer Vision**: YOLOv8 object detection + MediaPipe pose estimation  
- ðŸ§  **Spatial Reasoning**: Analyzes object positions and relationships  
- ðŸ“ **Natural Language Generation**: Uses LLaMA 3.2 for storytelling  
- ðŸ”Š **Speech Synthesis**: Converts story text into voice using gTTS  
- âš¡ **End-to-End AI**: Fully automated pipeline from image input to audio output

---

## ðŸ› ï¸ Tech Stack

- **Backend**: Python
- **Object Detection**: [YOLOv8x](https://github.com/ultralytics/ultralytics)
- **Pose Estimation**: [MediaPipe](https://developers.google.com/mediapipe)
- **LLM**: LLaMA 3.2 via [Ollama](https://ollama.com)
- **TTS**: gTTS (Google Text-to-Speech)
- **CV**: OpenCV

---

## ðŸ§° Requirements

- Python 3.8+
- YOLOv8 model file (`yolov8x.pt`)
- Ollama installed and running
- LLaMA 3.2 model pulled:  
  ```bash
  ollama pull llama3
  ```

---

## ðŸ Native Python Installation

1. Clone the repository:
```bash
git clone https://github.com/srimadhavn/EchoFrame.git
cd EchoFrame
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run the app:
```bash
python main.py --image inputs/image.png
```

---

## ðŸ³ Docker Installation (Recommended)

### ðŸ”¨ Build Docker Image
```bash
docker build -t echoframe .
```

### â–¶ï¸ Run with Docker
```bash
docker run -it --rm \
  -v $(pwd)/inputs:/app/inputs \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/yolov8x.pt:/app/yolov8x.pt \
  echoframe --image inputs/image.png
```

> ðŸ§  Note: This mounts your local folders into the container for input/output access.

---

## ðŸ“¦ Output Files

- `output/annotated.jpg` â€” Annotated image with visual detections  
- `output/story.txt` â€” Narrative text generated by LLaMA  
- `output/story.mp3` â€” Audio narration using gTTS

---

## ðŸŒŸ Why EchoFrame?

EchoFrame is a complete multi-modal storytelling pipeline, showing the power of combining:

- Visual Understanding  
- Scene Reasoning  
- Generative Language Models  
- Natural Speech Output  

---

## ðŸ“„ License

MIT License Â© 2025 Sri Madhavan
